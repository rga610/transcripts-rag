# **Financial Call Transcript RAG Assistant (MVP)**

---

## **1. Product Summary**

The Financial Call Transcript RAG Assistant is a lightweight web application that allows users to upload company earnings call transcripts (PDFs) and ask natural-language questions about management commentary, guidance, margins, risks, demand trends, or other financial topics.

The system uses **Retrieval-Augmented Generation (RAG)** with a managed vector database (Supabase + pgvector) and an LLM (OpenAI GPT-4.1-mini) to return accurate answers grounded in the documents.

The goal: **help students and analysts quickly extract insights from long transcripts** without manually reading them end-to-end.

---

## **2. User Goals**

Users should be able to:

1. Upload one or more conference call PDF transcripts.
2. Ask questions about financial commentary (e.g., “What did management say about FY2025 margins?”).
3. Receive accurate, concise answers grounded directly in the transcripts.
4. View a chat-like conversation history.
5. Optionally return later and retrieve previous conversations.

---

## **3. Key Features (MVP)**

### **3.1 Upload & Ingestion**

* Users upload PDF files via the UI.
* System extracts text, splits into chunks, generates embeddings.
* Chunks + metadata stored in Supabase (pgvector table).

### **3.2 Question Answering (RAG)**

* User asks a question in the chat UI.
* System retrieves relevant transcript chunks from Supabase.
* LLM uses retrieved context to answer the question.
* Answer is concise, analytical, and cites which transcript it came from (high-level, not page-perfect).

### **3.3 Chat UI**

* A clean Streamlit-based chat interface.
* Messages appear in “user” and “assistant” bubbles.
* Conversation persists within the session.

### **3.4 Conversation Logging**

Stored in Supabase:

**Table: conversations**

* id (uuid)
* created_at
* title (optional)
* metadata (jsonb)

**Table: messages**

* id (uuid)
* conversation_id (fk)
* role (user/assistant)
* content (text)
* created_at

Logging is transparent to the user (no account system required in MVP).

---

## **4. Non-Goals (Not in MVP)**

These are explicitly **excluded** to keep scope manageable:

* No web search fallback (e.g., Tavily).
* No speaker-level segmentation or sentiment analysis.
* No multi-user authentication system.
* No advanced analytics dashboard.
* No multi-document comparison logic (LLM can still answer if asked).

---

## **5. Functional Requirements**

### **5.1 Upload**

* Must accept PDF files up to ~10MB.
* Must allow multiple uploads.
* Must rebuild vector index when new files added.

### **5.2 Vector Store**

* Must store embeddings using OpenAI `text-embedding-3-small`.
* Must support similarity search with top-k retrieval.
* Must allow basic metadata fields such as filename.

### **5.3 Query Processing**

The system must:

1. Accept free-text financial questions.
2. Retrieve relevant transcript chunks.
3. Construct a LangChain prompt including:

   * Instructions
   * Retrieved context
   * User question
4. Call OpenAI GPT-4.1-mini.
5. Return the formatted answer.

### **5.4 Chat History**

* Every question & answer stored in Supabase.
* Session state in Streamlit stores temporary history.
* Page reload resets session unless conversation resume is implemented (optional).

---

## **6. Technical Stack**

### **6.1 Backend Logic (in Streamlit app itself)**

* **Python 3.11+**
* **LangChain**
* **OpenAI API** (`gpt-4.1-mini` + `text-embedding-3-small`)
* **PDF loading:** LangChain community loaders
* **Text splitting:** RecursiveCharacterTextSplitter

### **6.2 Database**

* **Supabase Postgres with pgvector**

  * Table for document chunks (vector index)
  * Tables for conversations & messages

### **6.3 Frontend**

* **Streamlit**

  * Chat UI components
  * PDF upload widget
  * Session state for message history

---

## **7. User Flow**

### **1. User visits the app**

Streamlit loads the chat interface.

### **2. User uploads transcripts**

Files saved temporarily on server → ingestion process runs → chunks stored in Supabase.

### **3. User asks a question**

User types into chat input.

### **4. Retrieval**

System queries pgvector for similar chunks.

### **5. LLM answer**

GPT-4.1-mini generates a concise, grounded summary.

### **6. Display**

Chat bubble shows answer; conversation logs to Supabase.

---

## **8. Success Criteria (MVP)**

### **Functional Criteria**

* User can upload at least 3–5 transcripts without failure.
* System answers at least 80% of questions using retrieved context.
* Chat UI is clean, responsive, and readable.
* Conversation logs correctly stored in Supabase.

### **Quality/UX Criteria**

* Answers are short, analytic, and non-hallucinatory.
* Retrieval returns relevant text chunks.
* No server crashes under normal usage.

### **Technical Criteria**

* Vector store queries < 300ms for typical load.
* Embedding generation completes within a few seconds per file.

---

## **9. Risks & Constraints**

### **Risks**

* Poor PDF formatting could reduce text extraction quality.
* LLM may hallucinate if retrieval fails.
* Supabase table misconfiguration could break vector search.

### **Constraints**

* Must remain simple enough for a student-level project.
* Should run on local machine + cloud-managed DB (no DevOps complexity).
* Costs must remain minimal (OpenAI usage + free Supabase tier).

---

## **10. Future Enhancements (Post-MVP)**

* Web search fallback (Tavily)
* Multi-document comparison pipeline
* Auto-summarization of entire transcript
* Company/industry classification
* Topic clustering & keyword extraction
* Authentication and user accounts
* Export conversation to PDF
* Deployment to Streamlit Cloud or Fly.io

---
